\section{Modellauswahl \& Evaluation}

\subsection{Was ist Hugging Face?}
Hugging Face ist ein Unternehmen, welches sich auf die Entwicklung von Künstlicher Intelligenz und Machine Learning spezialisiert hat. Auf der Seite huggingface.co werden verschiedenste vorgefertigte Modelle für zum Beispiel Textklassifikationen, Sentiment-Analysen, Übersetzungen und viele weitere Anwendungsfälle für Natural Language Processing (NLP) angeboten. Eines der bekanntesten Projekte von Hugging Face ist die \newline
Transformers-Bibliothek, welche Zugriff auf NLP-Modelle wie BERT, RoBERTa, DistilBERT oder GPT bietet. huggingface.co fördert eine Community-getriebene Entwicklung. Dies bedeutet, dass alle Modelle Open Source sind und frei genutzt werden können. Oft werden daher auch vorgelernte Modelle mithilfe spezifischer Datensätze für spezielle Aufgaben trainiert. Durch das breite Angebot von einfach verfügbaren Open Source NLP-Modellen, ist huggingface.co für dieses Projekt sehr gut geeignet.

\subsection{BERT-Modelle}
BERT (Bidirectional Encoder Representations from Transformers) ist ein Sprachmodell von Google, welches die Grundlage vieler moderner NLP-Modelle bildet. Es kann Kontexte verstehen und eignet sich dadurch gut für Sentiment-Analysen oder Emotionserkennung. Daher wurden für dieses Projekt vor allem Modelle, die auf BERT basieren, genutzt. Im Folgenden werden alle Modelle beschrieben und evaluiert.

\subsubsection{bhadresh-savani/distilbert-base-uncased-emotion}
Dieses Modell basiert auf DistilBERT, einer komprimierten Version von BERT, welche nur etwa 40\% Rechenleistung benötigt, bei nahezu vergleichbarer Genauigkeit zum BERT-Modell. Es wurde außerdem auf einem Datensatz aus Tweets für Emotionserkennung trainiert und klassifiziert in sechs Emotionen: anger, fear, joy, love, sadness, surprise. Da das DistilBERT Modell relativ schnell und speichereffizient ist, ist es ideal für Echtzeitanwendungen oder Anwendungen mit begrenzten Ressourcen. Auch da es auf Tweets trainiert ist, eignet es sich gut für dieses Projekt. Allerdings hat dieses Modell auch seine Grenzen. Komplexe und gemischte Gefühle lassen sich nicht abbilden, da das Modell einen Text immer nur mit einer Emotion klassifizieren kann. Zu lange Beiträge werden abgeschnitten, da das Modell nur mit einer begrenzten Anzahl an Tokens arbeiten kann.

\subsubsection{cardiffnlp/twitter-roberta-base-sentiment-latest}
Dieses Modell basiert auf RoBERTa, was eine verbesserte Version von BERT ist, es erziehlt genauere Ergebnisse, da für das Training größere Datenmengen genutzt werden. RoBERTa wurde speziell auf Tweets und anderen Social Media Texten trainiert und klassifiziert sie in positiv, neutral und negativ. Dieses Modell wurde auf sehr umfangreichen Tweet-Daten trainiert, daher erhält man mit ihm sehr genaue Ergebnisse, die aber nur in drei verschiedene Sentiments unterteilt werden. Das Modell ist deutlich leistungsstärker aber auch rechenintensiver als die BERT und DistilBERT Modelle. Außerdem gibt es bei diesem Modell in diesem Projekt manchmal einen Fehler. Nach Stichprobentests liegt die Vermutung nahe, dass hier zu lange Posts nicht abgeschnitten werden, sondern nur ebendieser Fehler angezeigt wird.

\subsubsection{j-hartmann/emotion-english-distilroberta-base}
Dieses Modell basiert auf DistilRoBERTa. Ähnlich wie bei DistilBERT ist es eine kleinere und schnellere Version von RoBERTa, die auf Emotionserkennung im Englischen spezialisiert ist. Dieses Modell ist mit Daten aus dem GoEmotions-Datensatz von Google trainiert, welcher über 58.000 englische Reddit-Kommentare beinhält. Dieses DistilRoBERTa Modell kann 28 verschiedene Emotionen erkennen, dadurch ist es möglich die erhaltenen Daten genauestens für verschiedenste Anwendungsfälle zu analysieren. Außerdem wurde es auf Reddit Kommentaren trainiert, was für den Anwendungsfall in diesem Projekt sehr gut geeignet ist. Durch die vielen Klassifizierungsmöglichkeiten wird allerdings auch das Interpretieren der Daten ohne Kontext schwer. So können Emotionen wie zum Beispiel fear oder surprise sowohl positiv als auch negativ interpretiert werden.

\subsubsection{tabularisai/multilingual-sentiment-analysis}
Dieses Modell basiert auf XLM-RoBERTa, ist also ähnlich wie RoBERTa, wurde allerdings auf vielen Sprachen gleichzeitig trainiert und kann daher in über 100 Sprachen Texte in positiv, neutral und negativ klassifizieren. Da bei allen anderen bisher diskutierten Modellen nur englischsprachige Testdaten genutzt wurden, hat dieses Modell den Vorteil, dass anderssprachige Posts nicht zuerst übersetzt werden müssen, womit die Laufzeit sinkt und Klassifikationsfehler auf Grund der Übersetzung minimiert werden. Allerdings klassifiziert dieses Modell auch nur sehr grob in positiv, neutral und negativ. Auch variiert die Genauigkeit nach Sprache, abhängig davon wie viel die Sprache in den Trainingsdaten vorhanden war.

\subsubsection{m-newhauser/distilbert-political-tweets}
Dieses Modell ist eine spezielle Version von DistilBERT und wurde vor allem auf politisch geprägten Tweets trainiert. Es ordnet Posts hinsichtlich der politischen Richtung ein. Ähnlich wie DistilBERT ist dieses Modell sehr effizient und durch die speziellen Trainingsdaten sehr gut für bestimmte Anwendungsfälle geeignet. Bei nicht-politischen Themen kann es aber zu falschen oder unpassenden Klassifikationen kommen.

\subsection{Evaluation}
Die verschiedenen Modelle haben alle ihre Vor- und Nachteile, welche je nach Anwendungsfall variieren können. In dem Fall dieses Projektes eignen sich DistilRoBERTa und DistilBERT am besten. Sie sind effizient, brauchen keine besonders hohe Rechenleistung und sind sehr genau beim Klassifizieren von Social Media Posts. Das RoBERTa Modell ist am besten geeignet, wenn es wichtig ist, dass die Ergebnisse exakt sind, aber keine breite Fächerung der Emotionen benötigt wird. Da die meisten Modelle nur auf Englisch trainiert wurden, kann es für anderssprachige Daten nützlich sein ein multilinguales Modell zu haben, dafür eignet sich das multilingual-sentiment-analysis Modell sehr gut. Rein englischsprachige Texte können allerdings besser von den anderen Modellen evaluiert werden. Modelle, wie das distilbert-political-tweets zeigen vor allem, wie leicht sich die BERT Modelle auch für Spezialfälle trainieren lassen. Zwar ist dies für dieses Projekt nicht nötig, für tatsächliche Anwendungsfälle kann es jedoch von Vorteil sein, ein Modell auf einen gewünschten Zweck zu spezialisieren. So könnten zum Beispiel Produktrezensionen genauer betrachtet und die Kundenzufriedenheit besser analysiert werden.